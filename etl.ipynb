{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14f0ffd9-54f7-41f8-a54d-0b3fed5e8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa dependencias e criar spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, dayofmonth, month, year, quarter, dayofweek\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"gaudium\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b34163ad-a85a-4137-a16b-9b52533db7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados brutos com esquema definido\n",
    "schema = StructType([\n",
    "    StructField(\"nome_cliente\", StringType(), True),\n",
    "    StructField(\"cidade\", StringType(), True),\n",
    "    StructField(\"estado\", StringType(), True),\n",
    "    StructField(\"nome_produto\", StringType(), True),\n",
    "    StructField(\"categoria\", StringType(), True),\n",
    "    StructField(\"fabricante\", StringType(), True),\n",
    "    StructField(\"data\", DateType(), True),\n",
    "    StructField(\"qtd_vendida\", IntegerType(), True),\n",
    "    StructField(\"valor_total\", IntegerType(), True),\n",
    "])\n",
    "tabela_vendas = spark.read.csv(\"tabelas/dados_brutos.csv\", header=True, schema=schema)\n",
    "tabela_vendas.createOrReplaceTempView(\"vendas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1e5e9bec-17c4-4ce2-8230-e8f1ca5250ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_categoria\n",
    "dim_categoria = spark.sql(\"SELECT DISTINCT(categoria) AS nome FROM vendas\")\n",
    "dim_categoria = dim_categoria.withColumn(\"id\", expr(\"uuid()\")).withColumnRenamed(\"categoria\", \"nome\")\n",
    "dim_categoria.createOrReplaceTempView(\"dim_categoria\")\n",
    "\n",
    "# dim_fabricante\n",
    "dim_fabricante = spark.sql(\"SELECT DISTINCT(fabricante) AS nome FROM vendas\")\n",
    "dim_fabricante = dim_fabricante.withColumn(\"id\", expr(\"uuid()\")).withColumnRenamed(\"fabricante\", \"nome\")\n",
    "dim_fabricante.createOrReplaceTempView(\"dim_fabricante\")\n",
    "\n",
    "# dim_produto\n",
    "dim_produto = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    DISTINCT(v.nome_produto) AS nome, c.id AS categoria_id, f.id AS fabricate_id\n",
    "FROM\n",
    "    vendas AS v\n",
    "JOIN\n",
    "    dim_categoria as c ON c.nome = categoria\n",
    "JOIN\n",
    "    dim_fabricante as f ON f.nome = fabricante\n",
    "\"\"\")\n",
    "dim_produto = dim_produto.withColumn(\"id\", expr(\"uuid()\"))\n",
    "dim_produto.createOrReplaceTempView(\"dim_produto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1c6aabab-3ce2-4752-8b2b-380b0d847288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_cliente\n",
    "dim_cliente = spark.sql(\"SELECT DISTINCT(nome_cliente) FROM vendas\")\n",
    "dim_cliente = dim_cliente.withColumn(\"id\", expr(\"uuid()\")).withColumnRenamed(\"nome_cliente\", \"nome\")\n",
    "dim_cliente.createOrReplaceTempView(\"dim_cliente\")\n",
    "\n",
    "# dim_endereco\n",
    "dim_endereco = spark.sql(\"SELECT DISTINCT cidade, estado FROM vendas\")\n",
    "dim_endereco = dim_endereco.withColumn(\"id\", expr(\"uuid()\"))\n",
    "dim_endereco.createOrReplaceTempView(\"dim_endereco\")\n",
    "\n",
    "# dim_data\n",
    "dim_data = spark.sql(\"SELECT DISTINCT(data) FROM vendas\")\n",
    "dim_data = dim_data.withColumn(\"dia\", dayofmonth(dim_data[\"data\"])) \\\n",
    "    .withColumn(\"mes\", month(dim_data[\"data\"])) \\\n",
    "    .withColumn(\"ano\", year(dim_data[\"data\"])) \\\n",
    "    .withColumn(\"trimestre\", quarter(dim_data[\"data\"])) \\\n",
    "    .withColumn(\"dia_semana\", dayofweek(dim_data[\"data\"]))\n",
    "dim_data.createOrReplaceTempView(\"dim_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77672509-6826-4c89-bc67-0281df4fab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fato_vendas\n",
    "fato_vendas = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    v.qtd_vendida, v.valor_total, data,\n",
    "    c.id AS cliente_id, e.id AS endereco_id, p.id AS produto_id\n",
    "FROM\n",
    "    vendas AS v\n",
    "JOIN\n",
    "    dim_cliente AS c ON c.nome = v.nome_cliente\n",
    "JOIN\n",
    "    dim_endereco AS e ON e.cidade = v.cidade AND e.estado = v.estado\n",
    "JOIN\n",
    "    dim_produto AS p ON p.nome = v.nome_produto\n",
    "\"\"\")\n",
    "fato_vendas.createOrReplaceTempView(\"fato_vendas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "417675a5-c437-44fd-9a43-4f44a0b10b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva as tabelas para arquivos .csv\n",
    "dim_categoria.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_categoria.csv\", mode=\"w\", index=False, header=True)\n",
    "dim_fabricante.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_fabricante.csv\", mode=\"w\", index=False, header=True)\n",
    "dim_produto.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_produto.csv\", mode=\"w\", index=False, header=True)\n",
    "dim_cliente.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_cliente.csv\", mode=\"w\", index=False, header=True)\n",
    "dim_endereco.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_endereco.csv\", mode=\"w\", index=False, header=True)\n",
    "dim_data.toPandas() \\\n",
    "    .to_csv(\"tabelas/dim_data.csv\", mode=\"w\", index=False, header=True)\n",
    "fato_vendas.toPandas() \\\n",
    "    .to_csv(\"tabelas/fato_vendas.csv\", mode=\"w\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
